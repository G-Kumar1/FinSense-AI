{
  "best_global_step": 987,
  "best_metric": 1.0842255353927612,
  "best_model_checkpoint": "models/fin_lora_adapter\\checkpoint-987",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 987,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.060790273556231005,
      "grad_norm": 12.942787170410156,
      "learning_rate": 1.961499493414387e-05,
      "loss": 10.7763,
      "step": 20
    },
    {
      "epoch": 0.12158054711246201,
      "grad_norm": 12.557429313659668,
      "learning_rate": 1.9209726443769e-05,
      "loss": 10.1369,
      "step": 40
    },
    {
      "epoch": 0.182370820668693,
      "grad_norm": 12.523421287536621,
      "learning_rate": 1.8804457953394124e-05,
      "loss": 9.256,
      "step": 60
    },
    {
      "epoch": 0.24316109422492402,
      "grad_norm": 13.129719734191895,
      "learning_rate": 1.8399189463019253e-05,
      "loss": 9.2701,
      "step": 80
    },
    {
      "epoch": 0.303951367781155,
      "grad_norm": 13.583281517028809,
      "learning_rate": 1.7993920972644378e-05,
      "loss": 8.1708,
      "step": 100
    },
    {
      "epoch": 0.364741641337386,
      "grad_norm": 13.357478141784668,
      "learning_rate": 1.7588652482269506e-05,
      "loss": 8.0547,
      "step": 120
    },
    {
      "epoch": 0.425531914893617,
      "grad_norm": 13.454794883728027,
      "learning_rate": 1.718338399189463e-05,
      "loss": 6.6965,
      "step": 140
    },
    {
      "epoch": 0.48632218844984804,
      "grad_norm": 16.24484634399414,
      "learning_rate": 1.6778115501519757e-05,
      "loss": 6.3437,
      "step": 160
    },
    {
      "epoch": 0.547112462006079,
      "grad_norm": 8.417076110839844,
      "learning_rate": 1.6372847011144886e-05,
      "loss": 4.9262,
      "step": 180
    },
    {
      "epoch": 0.60790273556231,
      "grad_norm": 14.77820873260498,
      "learning_rate": 1.596757852077001e-05,
      "loss": 4.9229,
      "step": 200
    },
    {
      "epoch": 0.668693009118541,
      "grad_norm": 10.477615356445312,
      "learning_rate": 1.556231003039514e-05,
      "loss": 4.719,
      "step": 220
    },
    {
      "epoch": 0.729483282674772,
      "grad_norm": 8.71389102935791,
      "learning_rate": 1.5157041540020265e-05,
      "loss": 3.7599,
      "step": 240
    },
    {
      "epoch": 0.790273556231003,
      "grad_norm": 8.93503189086914,
      "learning_rate": 1.475177304964539e-05,
      "loss": 3.6949,
      "step": 260
    },
    {
      "epoch": 0.851063829787234,
      "grad_norm": 8.761713027954102,
      "learning_rate": 1.4346504559270517e-05,
      "loss": 3.0158,
      "step": 280
    },
    {
      "epoch": 0.9118541033434651,
      "grad_norm": 6.362712383270264,
      "learning_rate": 1.3941236068895645e-05,
      "loss": 2.9178,
      "step": 300
    },
    {
      "epoch": 0.9726443768996961,
      "grad_norm": 7.04358434677124,
      "learning_rate": 1.353596757852077e-05,
      "loss": 2.8449,
      "step": 320
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.294017094017094,
      "eval_f1": 0.21318750225722116,
      "eval_loss": 2.395636796951294,
      "eval_runtime": 102.1647,
      "eval_samples_per_second": 5.726,
      "eval_steps_per_second": 0.724,
      "step": 329
    },
    {
      "epoch": 1.033434650455927,
      "grad_norm": 7.058454513549805,
      "learning_rate": 1.3130699088145898e-05,
      "loss": 2.3402,
      "step": 340
    },
    {
      "epoch": 1.094224924012158,
      "grad_norm": 7.687014102935791,
      "learning_rate": 1.2725430597771025e-05,
      "loss": 2.2825,
      "step": 360
    },
    {
      "epoch": 1.155015197568389,
      "grad_norm": 5.425514221191406,
      "learning_rate": 1.2320162107396151e-05,
      "loss": 1.8964,
      "step": 380
    },
    {
      "epoch": 1.21580547112462,
      "grad_norm": 7.129273414611816,
      "learning_rate": 1.1914893617021277e-05,
      "loss": 1.8981,
      "step": 400
    },
    {
      "epoch": 1.2765957446808511,
      "grad_norm": 8.175488471984863,
      "learning_rate": 1.1509625126646404e-05,
      "loss": 1.9261,
      "step": 420
    },
    {
      "epoch": 1.337386018237082,
      "grad_norm": 6.4382004737854,
      "learning_rate": 1.1104356636271532e-05,
      "loss": 1.5733,
      "step": 440
    },
    {
      "epoch": 1.3981762917933132,
      "grad_norm": 5.600333213806152,
      "learning_rate": 1.0699088145896657e-05,
      "loss": 1.6236,
      "step": 460
    },
    {
      "epoch": 1.458966565349544,
      "grad_norm": 8.71464729309082,
      "learning_rate": 1.0293819655521784e-05,
      "loss": 1.403,
      "step": 480
    },
    {
      "epoch": 1.5197568389057752,
      "grad_norm": 6.132575988769531,
      "learning_rate": 9.88855116514691e-06,
      "loss": 1.4001,
      "step": 500
    },
    {
      "epoch": 1.580547112462006,
      "grad_norm": 6.3417134284973145,
      "learning_rate": 9.483282674772038e-06,
      "loss": 1.4588,
      "step": 520
    },
    {
      "epoch": 1.641337386018237,
      "grad_norm": 4.9757280349731445,
      "learning_rate": 9.078014184397164e-06,
      "loss": 1.3301,
      "step": 540
    },
    {
      "epoch": 1.702127659574468,
      "grad_norm": 5.709784984588623,
      "learning_rate": 8.67274569402229e-06,
      "loss": 1.3282,
      "step": 560
    },
    {
      "epoch": 1.7629179331306992,
      "grad_norm": 6.435791015625,
      "learning_rate": 8.267477203647417e-06,
      "loss": 1.2794,
      "step": 580
    },
    {
      "epoch": 1.8237082066869301,
      "grad_norm": 9.999197006225586,
      "learning_rate": 7.862208713272543e-06,
      "loss": 1.3536,
      "step": 600
    },
    {
      "epoch": 1.884498480243161,
      "grad_norm": 5.5551557540893555,
      "learning_rate": 7.45694022289767e-06,
      "loss": 1.2197,
      "step": 620
    },
    {
      "epoch": 1.9452887537993921,
      "grad_norm": 8.274532318115234,
      "learning_rate": 7.0516717325227965e-06,
      "loss": 1.1947,
      "step": 640
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.4666666666666667,
      "eval_f1": 0.3326693795959163,
      "eval_loss": 1.2004185914993286,
      "eval_runtime": 100.3985,
      "eval_samples_per_second": 5.827,
      "eval_steps_per_second": 0.737,
      "step": 658
    },
    {
      "epoch": 2.0060790273556233,
      "grad_norm": 8.734707832336426,
      "learning_rate": 6.646403242147924e-06,
      "loss": 1.108,
      "step": 660
    },
    {
      "epoch": 2.066869300911854,
      "grad_norm": 5.3611955642700195,
      "learning_rate": 6.24113475177305e-06,
      "loss": 1.1456,
      "step": 680
    },
    {
      "epoch": 2.127659574468085,
      "grad_norm": 5.064103126525879,
      "learning_rate": 5.8358662613981764e-06,
      "loss": 1.2051,
      "step": 700
    },
    {
      "epoch": 2.188449848024316,
      "grad_norm": 3.852896213531494,
      "learning_rate": 5.430597771023303e-06,
      "loss": 1.182,
      "step": 720
    },
    {
      "epoch": 2.2492401215805473,
      "grad_norm": 3.152730941772461,
      "learning_rate": 5.02532928064843e-06,
      "loss": 1.217,
      "step": 740
    },
    {
      "epoch": 2.310030395136778,
      "grad_norm": 6.197154998779297,
      "learning_rate": 4.620060790273556e-06,
      "loss": 1.2085,
      "step": 760
    },
    {
      "epoch": 2.370820668693009,
      "grad_norm": 12.990876197814941,
      "learning_rate": 4.214792299898683e-06,
      "loss": 1.2208,
      "step": 780
    },
    {
      "epoch": 2.43161094224924,
      "grad_norm": 3.934901714324951,
      "learning_rate": 3.80952380952381e-06,
      "loss": 1.1975,
      "step": 800
    },
    {
      "epoch": 2.4924012158054714,
      "grad_norm": 8.741931915283203,
      "learning_rate": 3.4042553191489363e-06,
      "loss": 1.0245,
      "step": 820
    },
    {
      "epoch": 2.5531914893617023,
      "grad_norm": 6.32733154296875,
      "learning_rate": 2.9989868287740633e-06,
      "loss": 1.0716,
      "step": 840
    },
    {
      "epoch": 2.613981762917933,
      "grad_norm": 8.647096633911133,
      "learning_rate": 2.5937183383991898e-06,
      "loss": 1.1826,
      "step": 860
    },
    {
      "epoch": 2.674772036474164,
      "grad_norm": 3.1628007888793945,
      "learning_rate": 2.1884498480243163e-06,
      "loss": 1.1386,
      "step": 880
    },
    {
      "epoch": 2.735562310030395,
      "grad_norm": 5.614833831787109,
      "learning_rate": 1.7831813576494428e-06,
      "loss": 1.1541,
      "step": 900
    },
    {
      "epoch": 2.7963525835866263,
      "grad_norm": 8.933513641357422,
      "learning_rate": 1.3779128672745695e-06,
      "loss": 1.1264,
      "step": 920
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 4.126772880554199,
      "learning_rate": 9.726443768996962e-07,
      "loss": 1.1139,
      "step": 940
    },
    {
      "epoch": 2.917933130699088,
      "grad_norm": 3.3433361053466797,
      "learning_rate": 5.673758865248227e-07,
      "loss": 1.0939,
      "step": 960
    },
    {
      "epoch": 2.978723404255319,
      "grad_norm": 5.241882801055908,
      "learning_rate": 1.6210739614994936e-07,
      "loss": 1.133,
      "step": 980
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.4905982905982906,
      "eval_f1": 0.36077645440570855,
      "eval_loss": 1.0842255353927612,
      "eval_runtime": 55.9661,
      "eval_samples_per_second": 10.453,
      "eval_steps_per_second": 1.322,
      "step": 987
    }
  ],
  "logging_steps": 20,
  "max_steps": 987,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1042776388265472.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
